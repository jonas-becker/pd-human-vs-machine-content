{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snake\\miniconda3\\envs\\ir\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from re import sub\n",
    "import numpy as np\n",
    "from thefuzz import fuzz\n",
    "import shortuuid\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import sys\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex, SoftCosineSimilarity, Similarity\n",
    "from setup import *\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>is_paraphrase</th>\n",
       "      <th>text_embedding_1</th>\n",
       "      <th>text_embedding_2</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>LHjpHEXk</td>\n",
       "      <td>gwDCzrDa</td>\n",
       "      <td>Roy of the Rovers</td>\n",
       "      <td>Roy of the Rovers</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>eTWUFL9g</td>\n",
       "      <td>kcR9wLxs</td>\n",
       "      <td>Roy of the Rovers is a British comic strip abo...</td>\n",
       "      <td>Roy of the Rovers is a British funny cartoon a...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>KydYbt3U</td>\n",
       "      <td>M354NU7E</td>\n",
       "      <td>The weekly strip ran until 1993, following Roy...</td>\n",
       "      <td>The week after week strip kept running until 1...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>UiBxZ7ux</td>\n",
       "      <td>j5A8hRzD</td>\n",
       "      <td>Football-themed stories were a staple of Briti...</td>\n",
       "      <td>Football-themed stories were a staple of Briti...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>W2NyueS6</td>\n",
       "      <td>Q3kK3v3Z</td>\n",
       "      <td>The stock media phrase \"real 'Roy of the Rover...</td>\n",
       "      <td>The stock media express \"genuine 'Roy of the R...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset      id_1      id_2  \\\n",
       "0    DMoP  LHjpHEXk  gwDCzrDa   \n",
       "1    DMoP  eTWUFL9g  kcR9wLxs   \n",
       "2    DMoP  KydYbt3U  M354NU7E   \n",
       "3    DMoP  UiBxZ7ux  j5A8hRzD   \n",
       "4    DMoP  W2NyueS6  Q3kK3v3Z   \n",
       "\n",
       "                                              text_1  \\\n",
       "0                                  Roy of the Rovers   \n",
       "1  Roy of the Rovers is a British comic strip abo...   \n",
       "2  The weekly strip ran until 1993, following Roy...   \n",
       "3  Football-themed stories were a staple of Briti...   \n",
       "4  The stock media phrase \"real 'Roy of the Rover...   \n",
       "\n",
       "                                              text_2  is_paraphrase  \\\n",
       "0                                  Roy of the Rovers           True   \n",
       "1  Roy of the Rovers is a British funny cartoon a...           True   \n",
       "2  The week after week strip kept running until 1...           True   \n",
       "3  Football-themed stories were a staple of Briti...           True   \n",
       "4  The stock media express \"genuine 'Roy of the R...           True   \n",
       "\n",
       "  text_embedding_1 text_embedding_2 cosine_distance  \n",
       "0             None             None            None  \n",
       "1             None             None            None  \n",
       "2             None             None            None  \n",
       "3             None             None            None  \n",
       "4             None             None            None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(OUT_DIR, FORMATTED_DATA_FILENAME), orient = \"index\")\n",
    "df[TEXTEMBED1] = None\n",
    "df[TEXTEMBED2] = None\n",
    "df[COSINE_DISTANCE] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True )\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for paraprhases with the fuzzy-based method. Dataframe rows to process: 179661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 501/179661 [04:25<26:20:25,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#Check for paraphrase with fuzzy based\n",
    "t1_embeddings = []\n",
    "t2_embeddings = []\n",
    "print(\"Creating embeddings for each sentence (text1 % text2) and calculating their distances ...\")\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if i>500:\n",
    "        break\n",
    "\n",
    "    # mark the text with BERT special characters\n",
    "    t_1 = \"[CLS] \" + row[TEXT1].replace(\".\", \". [SEP][CLS]\") \n",
    "    t_2 = \"[CLS] \" + row[TEXT2].replace(\".\", \". [SEP][CLS]\") \n",
    "    if t_1.endswith(\"[CLS]\"):\n",
    "        t_1 = t_1[:-5]\n",
    "    if not t_1.endswith(\"[SEP]\"):\n",
    "        t_1 = t_1 + \" [SEP]\"\n",
    "    if t_2.endswith(\"[CLS]\"):\n",
    "        t_2 = t_2[:-5]\n",
    "    if not t_2.endswith(\"[SEP]\"):\n",
    "        t_2 = t_2 + \" [SEP]\"\n",
    "\n",
    "    # tokenize with BERT tokenizer\n",
    "    t1_tokenized = tokenizer.tokenize(t_1)\n",
    "    t2_tokenized = tokenizer.tokenize(t_2)\n",
    "\n",
    "    # throw out longer that 512 token texts because BERT model struggels to process them\n",
    "    if len(t1_tokenized) > 512 or len(t2_tokenized) > 512:\n",
    "        continue\n",
    "\n",
    "    # map tokens to vocab indices\n",
    "    t1_indexed = tokenizer.convert_tokens_to_ids(t1_tokenized)\n",
    "    t2_indexed = tokenizer.convert_tokens_to_ids(t2_tokenized)\n",
    "\n",
    "    t1_segments_ids = [1] * len(t1_tokenized)\n",
    "    t2_segments_ids = [1] * len(t2_tokenized)\n",
    "\n",
    "    #Extract Embeddings\n",
    "    t1_tensor = torch.tensor([t1_indexed])\n",
    "    t1_segments_tensors = torch.tensor([t1_segments_ids])\n",
    "    t2_tensor = torch.tensor([t2_indexed])\n",
    "    t2_segments_tensors = torch.tensor([t2_segments_ids])\n",
    "\n",
    "\n",
    "    # collect all of the hidden states produced from all layers \n",
    "    with torch.no_grad():\n",
    "        t1_hidden_states = model(t1_tensor, t1_segments_tensors)[2]\n",
    "        t2_hidden_states = model(t2_tensor, t2_segments_tensors)[2]\n",
    "\n",
    "    # Concatenate the tensors for all layers (reate a new dimension in the tensor)\n",
    "    t1_embeds = torch.stack(t1_hidden_states, dim=0)\n",
    "    t2_embeds = torch.stack(t2_hidden_states, dim=0)\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    t1_embeds = torch.squeeze(t1_embeds, dim=1)\n",
    "    t2_embeds = torch.squeeze(t2_embeds, dim=1)\n",
    "\n",
    "    #Switch dimensions\n",
    "    t1_embeds = t1_embeds.permute(1,0,2)\n",
    "    t2_embeds = t2_embeds.permute(1,0,2)\n",
    "\n",
    "    # Create Word Vector Representation for all tokens within the sentences\n",
    "    t1_token_vecs = []\n",
    "    t2_token_vecs = []\n",
    "    for token in t1_embeds:\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        t1_token_vecs.append(cat_vec)\n",
    "    for token in t2_embeds:\n",
    "        # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        t2_token_vecs.append(cat_vec)\n",
    "\n",
    "    # Create Sentence Vector Representations (average of all token vectors)\n",
    "    text1_embedding = torch.mean(t1_hidden_states[-2][0], dim=0)\n",
    "    text2_embedding = torch.mean(t2_hidden_states[-2][0], dim=0)\n",
    "\n",
    "    cos_distance = 1 - cosine(text1_embedding, text2_embedding)\n",
    "\n",
    "    df.at[i, TEXTEMBED1] = text1_embedding\n",
    "    df.at[i, TEXTEMBED2] = text2_embedding\n",
    "    df.at[i, COSINE_DISTANCE] = cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id_1</th>\n",
       "      <th>id_2</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>is_paraphrase</th>\n",
       "      <th>text_embedding_1</th>\n",
       "      <th>text_embedding_2</th>\n",
       "      <th>cosine_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>LHjpHEXk</td>\n",
       "      <td>gwDCzrDa</td>\n",
       "      <td>Roy of the Rovers</td>\n",
       "      <td>Roy of the Rovers</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.4072), tensor(0.0276), tensor(-0.27...</td>\n",
       "      <td>[tensor(-0.4072), tensor(0.0276), tensor(-0.27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>eTWUFL9g</td>\n",
       "      <td>kcR9wLxs</td>\n",
       "      <td>Roy of the Rovers is a British comic strip abo...</td>\n",
       "      <td>Roy of the Rovers is a British funny cartoon a...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.7420), tensor(-0.1898), tensor(0.26...</td>\n",
       "      <td>[tensor(-0.6134), tensor(-0.1051), tensor(0.30...</td>\n",
       "      <td>0.979295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>KydYbt3U</td>\n",
       "      <td>M354NU7E</td>\n",
       "      <td>The weekly strip ran until 1993, following Roy...</td>\n",
       "      <td>The week after week strip kept running until 1...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.7921), tensor(-0.3342), tensor(0.19...</td>\n",
       "      <td>[tensor(-0.9006), tensor(-0.3374), tensor(0.20...</td>\n",
       "      <td>0.958392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>UiBxZ7ux</td>\n",
       "      <td>j5A8hRzD</td>\n",
       "      <td>Football-themed stories were a staple of Briti...</td>\n",
       "      <td>Football-themed stories were a staple of Briti...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.6070), tensor(-0.3094), tensor(-0.0...</td>\n",
       "      <td>[tensor(-0.4892), tensor(-0.1072), tensor(0.19...</td>\n",
       "      <td>0.960228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DMoP</td>\n",
       "      <td>W2NyueS6</td>\n",
       "      <td>Q3kK3v3Z</td>\n",
       "      <td>The stock media phrase \"real 'Roy of the Rover...</td>\n",
       "      <td>The stock media express \"genuine 'Roy of the R...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(0.1027), tensor(0.2486), tensor(0.1573...</td>\n",
       "      <td>[tensor(-0.1071), tensor(0.3589), tensor(0.311...</td>\n",
       "      <td>0.97198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>1967578</td>\n",
       "      <td>1967664</td>\n",
       "      <td>The decision to issue new guidance has been pr...</td>\n",
       "      <td>Scotland Yard's decision to issue new guidance...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.1433), tensor(-0.5085), tensor(-0.0...</td>\n",
       "      <td>[tensor(-0.1010), tensor(-0.7359), tensor(-0.1...</td>\n",
       "      <td>0.959953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>317570</td>\n",
       "      <td>317290</td>\n",
       "      <td>The memo on protecting sales of Windows and ot...</td>\n",
       "      <td>The memo specifically mentioned Linux, a still...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.4673), tensor(0.0027), tensor(0.329...</td>\n",
       "      <td>[tensor(-0.3790), tensor(-0.3315), tensor(0.00...</td>\n",
       "      <td>0.96594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>2047034</td>\n",
       "      <td>2046820</td>\n",
       "      <td>Unable to find a home for him, a judge told me...</td>\n",
       "      <td>The judge had told the state Department of Men...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.0604), tensor(0.0570), tensor(-0.19...</td>\n",
       "      <td>[tensor(0.0215), tensor(-0.0550), tensor(-0.27...</td>\n",
       "      <td>0.92392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>84518</td>\n",
       "      <td>84541</td>\n",
       "      <td>Also Tuesday, the United States also released ...</td>\n",
       "      <td>Meanwhile in southern Iraq, the United States ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.1560), tensor(-0.0777), tensor(0.10...</td>\n",
       "      <td>[tensor(0.1307), tensor(-0.2524), tensor(-0.28...</td>\n",
       "      <td>0.947375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>2046630</td>\n",
       "      <td>2046644</td>\n",
       "      <td>The decision came a year after Whipple ended f...</td>\n",
       "      <td>The decision came a year after Whipple ended f...</td>\n",
       "      <td>True</td>\n",
       "      <td>[tensor(-0.5048), tensor(-0.1731), tensor(-0.3...</td>\n",
       "      <td>[tensor(-0.5400), tensor(-0.3178), tensor(-0.3...</td>\n",
       "      <td>0.976812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset      id_1      id_2  \\\n",
       "0      DMoP  LHjpHEXk  gwDCzrDa   \n",
       "1      DMoP  eTWUFL9g  kcR9wLxs   \n",
       "2      DMoP  KydYbt3U  M354NU7E   \n",
       "3      DMoP  UiBxZ7ux  j5A8hRzD   \n",
       "4      DMoP  W2NyueS6  Q3kK3v3Z   \n",
       "..      ...       ...       ...   \n",
       "495    MSRP   1967578   1967664   \n",
       "496    MSRP    317570    317290   \n",
       "497    MSRP   2047034   2046820   \n",
       "498    MSRP     84518     84541   \n",
       "499    MSRP   2046630   2046644   \n",
       "\n",
       "                                                text_1  \\\n",
       "0                                    Roy of the Rovers   \n",
       "1    Roy of the Rovers is a British comic strip abo...   \n",
       "2    The weekly strip ran until 1993, following Roy...   \n",
       "3    Football-themed stories were a staple of Briti...   \n",
       "4    The stock media phrase \"real 'Roy of the Rover...   \n",
       "..                                                 ...   \n",
       "495  The decision to issue new guidance has been pr...   \n",
       "496  The memo on protecting sales of Windows and ot...   \n",
       "497  Unable to find a home for him, a judge told me...   \n",
       "498  Also Tuesday, the United States also released ...   \n",
       "499  The decision came a year after Whipple ended f...   \n",
       "\n",
       "                                                text_2  is_paraphrase  \\\n",
       "0                                    Roy of the Rovers           True   \n",
       "1    Roy of the Rovers is a British funny cartoon a...           True   \n",
       "2    The week after week strip kept running until 1...           True   \n",
       "3    Football-themed stories were a staple of Briti...           True   \n",
       "4    The stock media express \"genuine 'Roy of the R...           True   \n",
       "..                                                 ...            ...   \n",
       "495  Scotland Yard's decision to issue new guidance...           True   \n",
       "496  The memo specifically mentioned Linux, a still...           True   \n",
       "497  The judge had told the state Department of Men...           True   \n",
       "498  Meanwhile in southern Iraq, the United States ...           True   \n",
       "499  The decision came a year after Whipple ended f...           True   \n",
       "\n",
       "                                      text_embedding_1  \\\n",
       "0    [tensor(-0.4072), tensor(0.0276), tensor(-0.27...   \n",
       "1    [tensor(-0.7420), tensor(-0.1898), tensor(0.26...   \n",
       "2    [tensor(-0.7921), tensor(-0.3342), tensor(0.19...   \n",
       "3    [tensor(-0.6070), tensor(-0.3094), tensor(-0.0...   \n",
       "4    [tensor(0.1027), tensor(0.2486), tensor(0.1573...   \n",
       "..                                                 ...   \n",
       "495  [tensor(-0.1433), tensor(-0.5085), tensor(-0.0...   \n",
       "496  [tensor(-0.4673), tensor(0.0027), tensor(0.329...   \n",
       "497  [tensor(-0.0604), tensor(0.0570), tensor(-0.19...   \n",
       "498  [tensor(-0.1560), tensor(-0.0777), tensor(0.10...   \n",
       "499  [tensor(-0.5048), tensor(-0.1731), tensor(-0.3...   \n",
       "\n",
       "                                      text_embedding_2 cosine_distance  \n",
       "0    [tensor(-0.4072), tensor(0.0276), tensor(-0.27...               1  \n",
       "1    [tensor(-0.6134), tensor(-0.1051), tensor(0.30...        0.979295  \n",
       "2    [tensor(-0.9006), tensor(-0.3374), tensor(0.20...        0.958392  \n",
       "3    [tensor(-0.4892), tensor(-0.1072), tensor(0.19...        0.960228  \n",
       "4    [tensor(-0.1071), tensor(0.3589), tensor(0.311...         0.97198  \n",
       "..                                                 ...             ...  \n",
       "495  [tensor(-0.1010), tensor(-0.7359), tensor(-0.1...        0.959953  \n",
       "496  [tensor(-0.3790), tensor(-0.3315), tensor(0.00...         0.96594  \n",
       "497  [tensor(0.0215), tensor(-0.0550), tensor(-0.27...         0.92392  \n",
       "498  [tensor(0.1307), tensor(-0.2524), tensor(-0.28...        0.947375  \n",
       "499  [tensor(-0.5400), tensor(-0.3178), tensor(-0.3...        0.976812  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(500)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba8ccf737b15cd80d270f3c9a5662f183ffa2a8eee196c58873fb7075cc0cb1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
